{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walking Experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walking sequences were taken from the CMU mocap database in order to build a training and validation set. Specifically the subject #7 was used with the trails ['01', '02', '03', '06', '07', '08', '09'] for training and trials ['10', '11'] for validation. The outputs of interest are both tibias and both radiuses?. For more details see `mocap_extraction_script.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations gathered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/ObservationsPlot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Output (SO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is still failing to achieve good fits for multiple-output observations. Therefore the following results are based on a single output (the blue one above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferred Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'spring': array([[ 0.0005],\n",
    "       [ 0.0005],\n",
    "       [ 0.0005]]), 'lengthscales': array([[ 0.00999595],\n",
    "       [ 0.00130432],\n",
    "       [ 0.00150659]]), 'sensi': array([[[-25.77900169]],\n",
    "\n",
    "       [[-53.23964169]],\n",
    "\n",
    "       [[-24.00917431]]]), 'noise_var': array([ 0.0005]), 'damper': array([[ 48.36195206],\n",
    "       [ 63.04325901],\n",
    "       [ 66.75989561]])}\n",
    "#\n",
    "array([[  2.96283135e-02,   9.36177573e-01,   3.41941139e-02],\n",
    "       [  5.84637524e-01,   4.96611806e-05,   4.15312814e-01],\n",
    "       [  1.91467122e-01,   4.34857976e-01,   3.73674902e-01]])\n",
    "#\n",
    "array([  1.00000000e+000,   1.99953753e-120,   0.00000000e+000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Viterbi for training\n",
    "[array([0, 1, 0, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 0, 1, 0])\n",
    " array([0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 1, 2, 1, 0, 0, 1])\n",
    " array([0, 1, 0, 2, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 2, 0, 1, 0, 1, 2, 2])\n",
    " array([0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1])\n",
    " array([0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 2, 0, 1, 0, 1])\n",
    " array([0, 1, 0, 1, 2, 2, 1, 2, 0, 1, 0, 1, 2])\n",
    " array([0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2])]\n",
    "Viterbi for testing\n",
    "[array([0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2])\n",
    " array([0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligned results for gait cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Training\n",
    "\n",
    "First periodic part\n",
    "0, 1, 0, 1, 2, 1, 2\n",
    "0, 1, 0, 1, 2, 0, 1\n",
    "0, 1, 0, 2, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "Second periodic part\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "\n",
    "Testing\n",
    "\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "0, 1, 0, 1, 2, 1, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting Fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Training Observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/FirstTrainingObservationFit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Testing Observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/FirstTestingObservationFit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Testing Observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/SecondTestingObservationFit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:** Notice that the above results are based on an algorithm which optimizes the sensitivities. I carried out another experiment where the sensitivities are set to one. The results in the latter setting also exhibits an interesting pattern and seems to do less overfitting (this has not been validated tough). To reproduce the reported experiment use the parameters stored in the ipython cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is an interesting pattern during each gait period. However, when the parameters for each hidden state are analysed there is something weird, the spring for each hidden state is the minimum possible value (i.e. 0.0005) which can be interpreted as all the dynamical systems being over-damped.\n",
    "* When the multiple-output model is inferred it seems to me that the fitting is always performing poorly except for a single output which is well-fitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Output (MO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was mentioned above, the resulting fit for multiple output is not good. Here we show some of the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_bad_fit_lfm.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the there is only one output that is well-fitted. However, the rest of the outputs are very badly approximated. This can be due to the use of a single latent force. As for the viterbi sequence, the model is explaining all the segments with a single hidden state which is weird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise fixed to 0.005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_bad_fit_lfm_fixed_noise.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By fixing the noise it seems that the model achieves a better trade-off between the different outputs in contrast with the the fit obtained with free parameters. However, the model is still far of inferring an overall good fit. A remarkable result is that this time the Viterbi sequence was more diverse and it exhibits an interesting pattern which is shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"Viterbi for training\"\n",
    "[array([2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2])\n",
    " array([2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2])\n",
    " array([2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0])\n",
    " array([2, 2, 2, 1, 0, 1, 1, 2, 2, 2, 1, 0, 1, 1, 2, 2])\n",
    " array([2, 2, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1])\n",
    " array([2, 2, 2, 2, 0, 1, 1, 0, 2, 2, 2, 2, 0])\n",
    " array([2, 2, 2, 0, 0, 1, 2, 2, 2, 0, 0])]\n",
    "\"Viterbi for testing\"\n",
    "[array([2, 2, 2, 0, 1, 1, 2, 2, 2, 1, 0]) -> This corresponds to the plotted realization.\n",
    " array([2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Latent forces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_good_fit_lfm_3_forces.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the best multiple-output fit so far. Weird finding: the lenghtscales are too small **why?**. The viterbi sequences is kind of diverse although only two hidden states are being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Viterbi for training\n",
    "[array([1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1])\n",
    " array([1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2])\n",
    " array([1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2])]\n",
    "Viterbi for testing\n",
    "[array([1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2])\n",
    " array([1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the the HMM-LFM is not working properly over multiple-output sequences. A synthetic multiple-output observation sequence was used to validate the implementation and discard errors. The experiment was carried out in the following setting:\n",
    "\n",
    "* 4 outputs.\n",
    "* 1 latent force.\n",
    "* Sensitivities were fixed to 1 for training and generation. They were not estimated.\n",
    "* The noise variances were estimated but the lower limit was set too high (0.0005). A better result can be probably obtained by setting a smaller variance limit.\n",
    "* The generated observation was scaled afterwards for having an amplitude of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the resulting fit. Notice that the outputs tendencies were correctly recovered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/Toy_lfm_testing_idx_6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Viterbi sequence was perfectly recovered for the testing observation (idx 6) which is\n",
    "\n",
    "[2, 2, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model seems to be estimating the correct viterbi sequence indeed, for almost all segments.\n",
    "* A remarkable fact is that it could be working that good because the synthetic generation was also performed using a single latent force. Probably that's the reason why the model is failing while working with multiple-output since the single-latent-force assumption might be too weak for a real system. An interesting experiment could be to generate sequences with more than one latent force and see what happens when a single-latent-force model is used for inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
