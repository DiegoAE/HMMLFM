{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walking Experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walking sequences were taken from the CMU mocap database in order to build a training and validation set. Specifically the subject #7 was used with the trails ['01', '02', '03', '06', '07', '08', '09'] for training and trials ['10', '11'] for validation. The outputs of interest are both tibias and both radiuses?. For more details see `mocap_extraction_script.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations gathered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/ObservationsPlot.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Output (SO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is still failing to achieve good fits for multiple-output observations. Therefore the following results are based on a single output (the blue one above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferred Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'spring': array([[ 0.0005],\n",
    "       [ 0.0005],\n",
    "       [ 0.0005]]), 'lengthscales': array([[ 0.00999595],\n",
    "       [ 0.00130432],\n",
    "       [ 0.00150659]]), 'sensi': array([[[-25.77900169]],\n",
    "\n",
    "       [[-53.23964169]],\n",
    "\n",
    "       [[-24.00917431]]]), 'noise_var': array([ 0.0005]), 'damper': array([[ 48.36195206],\n",
    "       [ 63.04325901],\n",
    "       [ 66.75989561]])}\n",
    "#\n",
    "array([[  2.96283135e-02,   9.36177573e-01,   3.41941139e-02],\n",
    "       [  5.84637524e-01,   4.96611806e-05,   4.15312814e-01],\n",
    "       [  1.91467122e-01,   4.34857976e-01,   3.73674902e-01]])\n",
    "#\n",
    "array([  1.00000000e+000,   1.99953753e-120,   0.00000000e+000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Viterbi for training\n",
    "[array([0, 1, 0, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 0, 1, 0])\n",
    " array([0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 1, 2, 1, 0, 0, 1])\n",
    " array([0, 1, 0, 2, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 2, 0, 1, 0, 1, 2, 2])\n",
    " array([0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1])\n",
    " array([0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 2, 0, 1, 0, 1])\n",
    " array([0, 1, 0, 1, 2, 2, 1, 2, 0, 1, 0, 1, 2])\n",
    " array([0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2])]\n",
    "Viterbi for testing\n",
    "[array([0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2])\n",
    " array([0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligned results for gait cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Training\n",
    "\n",
    "First periodic part\n",
    "0, 1, 0, 1, 2, 1, 2\n",
    "0, 1, 0, 1, 2, 0, 1\n",
    "0, 1, 0, 2, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "Second periodic part\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "0, 1, 0, 1, 2, 2, 1\n",
    "\n",
    "Testing\n",
    "\n",
    "0, 1, 0, 1, 2, 1, 0\n",
    "0, 1, 0, 1, 2, 1, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting Fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Training Observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/FirstTrainingObservationFit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Testing Observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/FirstTestingObservationFit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Testing Observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/SecondTestingObservationFit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:** Notice that the above results are based on an algorithm which optimizes the sensitivities. I carried out another experiment where the sensitivities are set to one. The results in the latter setting also exhibits an interesting pattern and seems to do less overfitting (this has not been validated tough). To reproduce the reported experiment use the parameters stored in the ipython cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is an interesting pattern during each gait period. However, when the parameters for each hidden state are analysed there is something weird, the spring for each hidden state is the minimum possible value (i.e. 0.0005) which can be interpreted as all the dynamical systems being over-damped.\n",
    "* When the multiple-output model is inferred it seems to me that the fitting is always performing poorly except for a single output which is well-fitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Output (MO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was mentioned above, the resulting fit for multiple output is not good. Here we show some of the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_bad_fit_lfm.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the there is only one output that is well-fitted. However, the rest of the outputs are very badly approximated. This can be due to the use of a single latent force. As for the viterbi sequence, the model is explaining all the segments with a single hidden state which is weird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise fixed to 0.005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_bad_fit_lfm_fixed_noise.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By fixing the noise it seems that the model achieves a better trade-off between the different outputs in contrast with the the fit obtained with free parameters. However, the model is still far of inferring an overall good fit. A remarkable result is that this time the Viterbi sequence was more diverse and it exhibits an interesting pattern which is shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"Viterbi for training\"\n",
    "[array([2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2])\n",
    " array([2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 1, 2, 2, 2])\n",
    " array([2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0])\n",
    " array([2, 2, 2, 1, 0, 1, 1, 2, 2, 2, 1, 0, 1, 1, 2, 2])\n",
    " array([2, 2, 2, 1, 0, 1, 1, 2, 2, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1])\n",
    " array([2, 2, 2, 2, 0, 1, 1, 0, 2, 2, 2, 2, 0])\n",
    " array([2, 2, 2, 0, 0, 1, 2, 2, 2, 0, 0])]\n",
    "\"Viterbi for testing\"\n",
    "[array([2, 2, 2, 0, 1, 1, 2, 2, 2, 1, 0]) -> This corresponds to the plotted realization.\n",
    " array([2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Latent forces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_good_fit_lfm_3_forces.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the best multiple-output fit so far. Weird finding: the lenghtscales are too small **why?**. The viterbi sequences is kind of diverse although only two hidden states are being used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Viterbi for training\n",
    "[array([1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1])\n",
    " array([1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2])\n",
    " array([1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2])\n",
    " array([1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2])]\n",
    "Viterbi for testing\n",
    "[array([1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2])\n",
    " array([1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Latent forces tying spring and damper constants across the hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_fit_lfm_3_forces_tying.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red and green outputs are relatively well-fitted. However, the resulting fit for the purple and blue outputs is poor at some segments. A remarkable fact is that the inferred systems for the different outputs are over-damped and the obtained Viterbi sequence does not exhibit a clear pattern and the hidden state 1 is rarely used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training\n",
    "0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2\n",
    "0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2\n",
    "0, 2, 2, 0, 1, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 2\n",
    "2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 0\n",
    "2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 0, 0\n",
    "0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 1\n",
    "1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0\n",
    "testing\n",
    "0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2\n",
    "1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recovered parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'spring': array([[  2.93139497,  18.30079616,  95.10669727,  65.83824742],\n",
    "       [  2.93139497,  18.30079616,  95.10669727,  65.83824742],\n",
    "       [  2.93139497,  18.30079616,  95.10669727,  65.83824742]]),\n",
    "'lengthscales': array([[ 27.39681479,  41.71170415,  32.62533449],\n",
    "       [ 56.50443366,  56.54150379,  62.58986604],\n",
    "       [ 48.96958038,   3.92858599,  48.06104829]]),\n",
    "'sensi': array([[[ -5.9815586 ,   5.08453093,  -0.67822096],\n",
    "        [-21.308609  , -11.55093997, -32.99302539],\n",
    "        [-25.28963494, -17.44235857,  36.00957686],\n",
    "        [ 18.79254116,   7.68479576,  -1.21845214]],\n",
    "\n",
    "       [[  3.09388552,   7.6088857 , -27.30298974],\n",
    "        [ -7.43767972, -20.51830461, -15.96095817],\n",
    "        [-26.35466477, -21.52101748,  -5.07435013],\n",
    "        [-10.62123949,  -4.17335087,  -3.50753669]],\n",
    "\n",
    "       [[ -0.7761344 ,  -0.98786424,  15.19502258],\n",
    "        [ -3.54338494,  -7.78505674, -28.9785922 ],\n",
    "        [ 46.39562119,   0.11990274,   5.02776874],\n",
    "        [-41.9525083 ,   0.95356024,  -7.34558011]]]),\n",
    "'noise_var': array([ 0.0005,  0.0005,  0.0005,  0.0005]),\n",
    "'damper': array([[  23.25746022,   95.72849884,  101.20885341,   83.5292922 ],\n",
    "       [  23.25746022,   95.72849884,  101.20885341,   83.5292922 ],\n",
    "       [  23.25746022,   95.72849884,  101.20885341,   83.5292922 ]])}\n",
    "#\n",
    "array([[  3.58555364e-01,   7.49383699e-02,   5.66506266e-01],\n",
    "       [  2.90122683e-01,   0.00000000e+00,   7.09877317e-01],\n",
    "       [  4.35409265e-01,   5.33142950e-61,   5.64590735e-01]])\n",
    "#\n",
    "array([ 0.56973092,  0.14454131,  0.28572777])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Latent forces tying spring and damper constants across the hidden states with an additional initialization resulting from single output training results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_fit_lfm_3_forces_tying_manual_init.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the result obtained without the ad-hoc initialization, this model got a good fit for two outputs and a not-so-good fit for the rest. The inferred systems were over-damped for all the hidden states, however, this time the state number 1 was used more often in contrast with the model without manual init. **As a conclusion**, the quality of the obtained fit is comparable in both cases (with and without initialization ) but the model with manual initialization exhibits a more interesting pattern over the Viterbi sequence and it uses all the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Viterbi\n",
    "[array([2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 0])\n",
    " array([2, 0, 2, 0, 1, 0, 2, 1, 2, 1, 0, 1, 0, 2, 2, 2])\n",
    " array([2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2, 2, 1, 1, 0])\n",
    " array([2, 2, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 0, 2])\n",
    " array([2, 2, 0, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1])\n",
    " array([2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
    " array([0, 2, 2, 1, 0, 1, 0, 2, 0, 1, 1])]\n",
    "Viterbi for testing\n",
    "[array([2, 2, 1, 0, 1, 1, 0, 2, 0, 1, 1])\n",
    " array([2, 2, 0, 0, 1, 0, 0, 2, 0, 1, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'spring': array([[ 2.26375521,  0.02050971,  0.63348244,  0.47070381],\n",
    "       [ 2.26375521,  0.02050971,  0.63348244,  0.47070381],\n",
    "       [ 2.26375521,  0.02050971,  0.63348244,  0.47070381]]),\n",
    " 'lengthscales': array([[ 2.73577417,  2.73577417,  5.22739176,  3.25747652],\n",
    "       [ 4.13952071,  4.13952071,  3.01511403,  3.07367867],\n",
    "       [ 3.66635557,  3.66635557,  3.43545426,  2.89463762]]),\n",
    " 'sensi': array([[[-0.75665021, -0.75665021,  0.89663602,  1.86929137],\n",
    "        [ 2.30297906,  2.30297906,  1.55604906,  3.0103509 ],\n",
    "        [ 0.30988674,  0.30988674,  0.79633208, -0.49970666],\n",
    "        [ 0.03337953,  0.03337953, -0.7461141 , -0.04264646]],\n",
    "\n",
    "       [[-0.23586402, -0.23586402,  1.45032382, -0.58283774],\n",
    "        [-1.00338358, -1.00338358,  3.02553083,  4.28181741],\n",
    "        [ 0.77055472,  0.77055472, -0.03121016,  0.22530817],\n",
    "        [-0.14447712, -0.14447712, -0.19100976, -0.49743838]],\n",
    "\n",
    "       [[-1.67211895, -1.67211895,  1.46997293, -1.45992836],\n",
    "        [ 0.21098934,  0.21098934,  2.07639352,  0.49378319],\n",
    "        [ 0.57121984,  0.57121984,  0.84139044,  0.2239764 ],\n",
    "        [-0.30200503, -0.30200503, -0.62073109,  0.29943183]]]),\n",
    " 'noise_var': array([ 0.0005,  0.0005,  0.0005,  0.0005]),\n",
    " 'damper': array([[ 30.19300913,  79.6124462 ,  57.34502792,  39.21852835],\n",
    "       [ 30.19300913,  79.6124462 ,  57.34502792,  39.21852835],\n",
    "       [ 30.19300913,  79.6124462 ,  57.34502792,  39.21852835]])}\n",
    "#\n",
    "array([[ 0.16760543,  0.5782441 ,  0.25415047],\n",
    "       [ 0.45276683,  0.43129675,  0.11593642],\n",
    "       [ 0.4161567 ,  0.23831724,  0.34552607]])\n",
    "#\n",
    "array([  1.42870611e-001,   1.75782163e-141,   8.57129389e-001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Latent forces and 7 hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most time-consuming experiment carried out so far. It took about 48 hours. The following is the resulting fit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_fit_lfm_2_forces_7_hs.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again it seems that is **hard to capture the tendency of all outputs using only two latent forces** even tough a higher number of hidden states were used this time (7). The resulting Viterbi sequence was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Viterbi\n",
    "[2, 0, 2, 5, 2, 3, 2, 2, 2, 2, 5, 2, 3, 2, 2, 2]\n",
    "[2, 2, 2, 3, 2, 3, 2, 2, 2, 1, 3, 2, 3, 2, 2, 2]\n",
    "[2, 2, 2, 5, 5, 5, 6, 2, 2, 2, 2, 5, 5, 3, 4, 2, 2, 2, 3, 5, 3]\n",
    "[2, 2, 2, 6, 5, 3, 6, 2, 2, 2, 2, 5, 3, 6, 2, 2]\n",
    "[2, 2, 2, 6, 5, 3, 6, 2, 2, 2, 2, 5, 2, 6, 2, 2, 2, 2, 6]\n",
    "[2, 2, 2, 2, 5, 3, 6, 5, 2, 2, 2, 2, 5]\n",
    "[2, 2, 2, 5, 2, 6, 2, 2, 2, 2, 5]\n",
    "Viterbi for testing\n",
    "[2, 2, 1, 3, 2, 6, 2, 2, 2, 2, 5]\n",
    "[2, 2, 2, 3, 2, 6, 2, 2, 2, 2, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferred parameters were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'spring': array([[  1.82374845e+02,   1.71018570e+00,   4.18465831e-01, 1.36157839e+01],\n",
    "                  [  3.50612830e+00,   2.83941850e+01,   2.79386196e+00, 3.18151091e+00],\n",
    "                  [  9.86856587e-01,   1.68799492e+00,   1.97683935e+02, 4.50003111e+00],\n",
    "                  [  1.57974504e+01,   1.69076917e+01,   1.08610316e-03, 3.95237113e+01],\n",
    "                  [  6.37305272e+00,   2.74802121e+01,   1.77127686e+01, 9.45147959e+00],\n",
    "                  [  5.55062721e+01,   1.66840900e+00,   5.00000000e-04, 4.24032103e+01],\n",
    "                  [  3.28458556e+01,   2.33700891e+01,   3.62349966e+00, 8.34707673e+00]]),\n",
    " \n",
    " 'lengthscales': array([[  1.49834060e+00,   1.41007613e+00],\n",
    "       [  5.72184091e+02,   1.84040185e+02],\n",
    "       [  6.75601304e+01,   5.83983758e+01],\n",
    "       [  1.97708225e+02,   2.38576374e+02],\n",
    "       [  2.75847586e+01,   3.91543854e-01],\n",
    "       [  4.46208152e+00,   5.00000000e-04],\n",
    "       [  9.50977263e+00,   4.35504528e+00]]), 'sensi': array([[[ -5.54404454e+01,  -5.57062447e+01],\n",
    "        [  2.47059077e-01,   4.11821374e-01],\n",
    "        [  4.43076195e-01,   7.57875862e-01],\n",
    "        [  2.90284624e+00,   2.29988053e+00]],\n",
    "\n",
    "       [[ -4.17118076e+00,  -2.14502925e+00],\n",
    "        [ -2.63693110e+01,  -1.67825276e+01],\n",
    "        [ -2.12452423e+00,  -1.63204146e+00],\n",
    "        [ -3.87460853e-01,  -1.71054590e+00]],\n",
    "\n",
    "       [[ -1.30680498e+00,   2.29773226e+00],\n",
    "        [ -2.11543178e+00,   1.99824440e-01],\n",
    "        [ -9.60129061e+01,  -3.13392934e+01],\n",
    "        [  2.71074428e+00,  -5.17147313e-02]],\n",
    "\n",
    "       [[ -8.48574629e+00,  -1.39821042e+01],\n",
    "        [ -1.68826490e+01,  -2.23225304e+01],\n",
    "        [ -7.25170188e-01,  -1.58087845e+00],\n",
    "        [ -1.37309907e+01,  -2.51928588e+01]],\n",
    "\n",
    "       [[ -6.05672871e+00,  -3.50771448e+00],\n",
    "        [ -2.07345291e+01,  -1.08228004e+01],\n",
    "        [ -1.70374450e+01,  -1.65473526e+01],\n",
    "        [ -7.53049944e+00,  -4.59768059e+00]],\n",
    "\n",
    "       [[ -1.14353460e+01,  -2.26516361e+01],\n",
    "        [  2.91234202e+00,   1.34904159e+00],\n",
    "        [ -2.33731605e-01,  -3.40405348e+00],\n",
    "        [ -1.50059463e+01,  -1.78627608e+01]],\n",
    "\n",
    "       [[ -2.28932586e+01,  -1.34739690e+01],\n",
    "        [ -1.72700156e+01,  -1.04687220e+01],\n",
    "        [ -2.02037734e+00,  -2.56166821e+00],\n",
    "        [ -6.41268578e+00,  -6.56411256e+00]]]), 'noise_var': array([ 0.0007888 ,  0.00181349,  0.0005,  0.0005    ]),\n",
    " \n",
    " 'damper': array([[  1.70191631e+02,   2.15458593e+00,   2.08334985e+00, 9.18570916e-01],\n",
    "                  [  4.07503626e+00,   3.70273846e+01,   4.13952441e+00, 3.77438983e+00],\n",
    "                  [  2.43746343e+00,   4.87972511e+00,   1.70128731e+02, 3.67876210e+00],\n",
    "                  [  1.58666595e+01,   4.13903145e+01,   4.09524023e+00, 3.04724744e+01],\n",
    "                  [  5.98766650e+00,   2.03051628e+01,   3.42448464e+01, 7.84740338e+00],\n",
    "                  [  4.30752331e+01,   5.00000696e-04,   4.31920707e+00, 3.42765583e+01],\n",
    "                  [  2.52938971e+01,   1.84777144e+01,   4.00023749e+00, 1.09915182e+01]])}\n",
    "#\n",
    "array([[  0.00000000e+000,   0.00000000e+000,   1.00000000e+000,\n",
    "          0.00000000e+000,   0.00000000e+000,   4.96481524e-218,\n",
    "          0.00000000e+000],\n",
    "       [  0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
    "          1.00000000e+000,   0.00000000e+000,   5.96357583e-046,\n",
    "          0.00000000e+000],\n",
    "       [  1.51478575e-002,   1.51478438e-002,   6.51604403e-001,\n",
    "          8.79584274e-002,   0.00000000e+000,   1.51725385e-001,\n",
    "          7.84160835e-002],\n",
    "       [  0.00000000e+000,   0.00000000e+000,   5.08136953e-001,\n",
    "          1.43699783e-146,   8.46937602e-002,   6.83740068e-002,\n",
    "          3.38795280e-001],\n",
    "       [  0.00000000e+000,   0.00000000e+000,   1.00000000e+000,\n",
    "          0.00000000e+000,   0.00000000e+000,   0.00000000e+000,\n",
    "          0.00000000e+000],\n",
    "       [  0.00000000e+000,   1.45782620e-106,   3.33330694e-001,\n",
    "          4.00026139e-001,   0.00000000e+000,   1.99992052e-001,\n",
    "          6.66511156e-002],\n",
    "       [  0.00000000e+000,   0.00000000e+000,   6.53830275e-001,\n",
    "          1.41656919e-228,   0.00000000e+000,   3.46169725e-001,\n",
    "          1.18762794e-142]])\n",
    "#\n",
    "array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting and diverse pattern appeared in the Viterbi sequence. However, there are some hidden states that are scarcely used (e.g. 0,1,4) and these states also exhibit a particular property in the transition matrix, namely they have only one state to go next with non-zero probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Latent Forces (not more constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/MO_good_fit_lfm_4_forces.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good quality of the fit demonstrates that the flexibility of the model is tremendously increased by a higher number of latent forces. I believe this is the most successful fit so far for MO. The following is the Viterbi sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Viterbi for training\n",
    "2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2\n",
    "2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2\n",
    "2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1\n",
    "2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2\n",
    "2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1\n",
    "2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1\n",
    "2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1\n",
    "Viterbi for testing\n",
    "2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1\n",
    "2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is definitely an interesting pattern for each gait cycle. However, there is still a hidden state which is not used. The following are the estimated hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'spring': array([[  1.99406025e+01,   2.13703538e+01,   2.39324049e-01,\n",
    "          9.14109369e+00],\n",
    "       [  1.37066211e+01,   5.73699677e+00,   5.00300880e-04,\n",
    "          1.78996551e+00],\n",
    "       [  5.00000000e-04,   4.20075365e+00,   5.00000000e-04,\n",
    "          5.62116623e+00]]), 'lengthscales': array([[  5.00000000e-04,   1.02822203e-01,   5.00000000e-04,\n",
    "          5.00000000e-04],\n",
    "       [  1.14276400e-03,   1.30527861e-03,   8.00395731e+01,\n",
    "          2.65312133e-03],\n",
    "       [  5.00000000e-04,   7.38143533e-04,   5.00000000e-04,\n",
    "          5.00000000e-04]]), 'sensi': array([[[-10.52312427,  -1.76568382,  -8.47013963, -10.46657458],\n",
    "        [ -9.96120737,  -5.6078782 ,  -8.14383564,  -9.91225596],\n",
    "        [ -9.09771217, -12.07505569,  -9.10636493,  -9.12158474],\n",
    "        [ -9.211858  ,   8.82220687,  -7.47294339,  -9.17558442]],\n",
    "\n",
    "       [[  3.30187936, -11.75165288, -17.18411585,  10.29469261],\n",
    "        [  2.69767057,   0.82324125, -36.33282139, -11.29669654],\n",
    "        [ -9.98339139,   4.12910568,   0.31774872,   1.5138733 ],\n",
    "        [  0.52171147, -15.64780725,   7.12672137,  -1.68482311]],\n",
    "\n",
    "       [[-17.43507763,  -8.69318258,  -0.79325269,  24.7356264 ],\n",
    "        [ 17.62252733, -21.57363798, -19.82370447,  -4.75813817],\n",
    "        [-21.60963096,  -8.86855914,  11.27826199, -16.12525276],\n",
    "        [ -4.5051792 ,  21.55415938, -17.97762024,  12.84159568]]]),\n",
    " 'noise_var': array([ 0.0005,  0.0005,  0.0005,  0.0005]),\n",
    " 'damper': array([[ 14.38135469,  14.33100737,  20.54509203,  17.04146358],\n",
    "       [ 21.23187142,  29.80656226,  25.76938986,  45.14627322],\n",
    "       [ 10.85991572,  27.73322377,  29.44393941,  28.09988311]])}\n",
    "#\n",
    "array([[  0.00000000e+000,   4.52482959e-014,   1.00000000e+000],\n",
    "       [  2.83872227e-291,   6.82381674e-001,   3.17618326e-001],\n",
    "       [  6.60359902e-191,   5.81820590e-001,   4.18179410e-001]])\n",
    "#\n",
    "array([  0.00000000e+000,   8.92410366e-246,   1.00000000e+000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to point out that all the lfm's are over-damped ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the the HMM-LFM is not working properly over multiple-output sequences. A synthetic multiple-output observation sequence was used to validate the implementation and discard errors. The experiment was carried out in the following setting:\n",
    "\n",
    "* 4 outputs.\n",
    "* 1 latent force.\n",
    "* Sensitivities were fixed to 1 for training and generation. They were not estimated.\n",
    "* The noise variances were estimated but the lower limit was set too high (0.0005). A better result can be probably obtained by setting a smaller variance limit.\n",
    "* The generated observation was scaled afterwards for having an amplitude of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the resulting fit. Notice that the outputs tendencies were correctly recovered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='figures/Toy_lfm_testing_idx_6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Viterbi sequence was perfectly recovered for the testing observation (idx 6) which is\n",
    "\n",
    "[2, 2, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The model seems to be estimating the correct viterbi sequence indeed, for almost all segments.\n",
    "* A remarkable fact is that it could be working that good because the synthetic generation was also performed using a single latent force. Probably that's the reason why the model is failing while working with multiple-output since the single-latent-force assumption might be too weak for a real system. An interesting experiment could be to generate sequences with more than one latent force and see what happens when a single-latent-force model is used for inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
